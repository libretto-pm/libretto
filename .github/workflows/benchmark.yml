name: Benchmarks

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

env:
  CARGO_TERM_COLOR: always

jobs:
  # Run benchmarks and compare against main baseline
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2
        with:
          key: bench

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gnuplot

      # Download baseline from previous runs (if exists)
      - name: Download baseline
        uses: actions/cache@v4
        with:
          path: target/criterion-baseline
          key: criterion-baseline-${{ runner.os }}-${{ github.base_ref || 'main' }}
          restore-keys: |
            criterion-baseline-${{ runner.os }}-main
            criterion-baseline-${{ runner.os }}-

      # Run benchmarks
      - name: Run benchmarks
        run: |
          # Copy baseline if exists
          if [ -d "target/criterion-baseline" ]; then
            cp -r target/criterion-baseline target/criterion
          fi

          # Run all benchmarks
          cargo bench --package libretto-bench 2>&1 | tee benchmark-output.txt

      # Save results as new baseline for main branch
      - name: Save baseline
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        uses: actions/cache/save@v4
        with:
          path: target/criterion
          key: criterion-baseline-${{ runner.os }}-main-${{ github.sha }}

      # Upload HTML reports as artifacts
      - name: Upload benchmark reports
        uses: actions/upload-artifact@v4
        with:
          name: criterion-reports
          path: target/criterion
          retention-days: 30

      # Check for performance regression
      - name: Check for regressions
        id: regression-check
        run: |
          # Parse benchmark output for significant regressions (>5%)
          REGRESSIONS=""

          # Look for "Performance has regressed" or significant slowdowns
          if grep -q "Performance has regressed" benchmark-output.txt; then
            REGRESSIONS=$(grep -A2 "Performance has regressed" benchmark-output.txt | head -20)
          fi

          if [ -n "$REGRESSIONS" ]; then
            echo "REGRESSIONS_FOUND=true" >> $GITHUB_OUTPUT
            echo "REGRESSION_DETAILS<<EOF" >> $GITHUB_OUTPUT
            echo "$REGRESSIONS" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "REGRESSIONS_FOUND=false" >> $GITHUB_OUTPUT
          fi

      # Post comment on PR with benchmark results
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const output = fs.readFileSync('benchmark-output.txt', 'utf8');

            // Extract summary lines
            const lines = output.split('\n');
            const summaryLines = lines.filter(line =>
              line.includes('time:') ||
              line.includes('Performance has') ||
              line.includes('No change')
            ).slice(0, 30);

            const hasRegressions = '${{ steps.regression-check.outputs.REGRESSIONS_FOUND }}' === 'true';
            const status = hasRegressions ? '‚ö†Ô∏è Performance Regressions Detected' : '‚úÖ No Performance Regressions';

            let body = `## Benchmark Results\n\n${status}\n\n`;
            body += `<details><summary>View benchmark summary</summary>\n\n\`\`\`\n`;
            body += summaryLines.join('\n') || 'No benchmark changes detected.';
            body += `\n\`\`\`\n</details>\n\n`;
            body += `üìä [View full report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('## Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body,
              });
            }

      # Fail if significant regressions found
      - name: Fail on regression
        if: steps.regression-check.outputs.REGRESSIONS_FOUND == 'true'
        run: |
          echo "::error::Performance regression detected!"
          echo "${{ steps.regression-check.outputs.REGRESSION_DETAILS }}"
          # Uncomment to fail the build on regression:
          # exit 1

  # Quick benchmark smoke test on other platforms
  benchmark-platforms:
    name: Benchmark (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [macos-latest, windows-latest]
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2
        with:
          key: bench-${{ matrix.os }}

      - name: Run smoke benchmarks
        run: |
          # Run a quick subset of benchmarks
          cargo bench --package libretto-bench --bench lockfile_operations -- --noplot

  # Memory profiling (optional, manual trigger)
  memory-profile:
    name: Memory Profile
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install valgrind
        run: sudo apt-get install -y valgrind

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2
        with:
          key: memory-profile

      - name: Run memory benchmarks
        run: |
          cargo bench --package libretto-bench --bench memory_benchmarks -- --noplot

      - name: Upload memory profile
        uses: actions/upload-artifact@v4
        with:
          name: memory-profile
          path: target/memory-profile
          retention-days: 7
